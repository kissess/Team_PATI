{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e73ec73-266e-4de2-bd2c-9870e8b2ed39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import scipy\n",
    "from ultralytics import YOLO\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7398116-d722-4784-9efe-04a6915b5fca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef2cb98f-5341-47cd-abf3-02e33ef88e68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#사용할 GPU 지정\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b94a0ce7-4bd0-49f6-a52a-6c72b0259ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3080 Ti\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "print(torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "039ba677-fc99-4f74-806a-10c57d89fa98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 운동 종목 이름 설정.\n",
    "EXC_NAME=\"Lunge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3308c795-3c7b-482c-b299-a330bc281271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#저장 위치 설정.\n",
    "save_path=\"F:\\\\ArrayData\\\\\"\n",
    "# 입력 이미지 폴더 경로\n",
    "image_folder = 'F:\\\\ArrayData\\\\Lunge'\n",
    "# 이미지 폴더 내의 모든 이미지 파일을 가져오기\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "#txt 파일용\n",
    "EXC_NAME=EXC_NAME+\".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "800f44f5-2d7e-4e86-9aae-b33a11369d8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 모델 및 가중치 로드\n",
    "model = YOLO('F:/build_vector/runs/pose/train3/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b425613-dea0-49b8-815d-462043016108",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 F:\\ArrayData\\Lunge\\136-1-1-05-Z39_D-0000004.jpg: 384x640 1 person, 157.0ms\n",
      "Speed: 2.0ms preprocess, 157.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keypoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m results\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 결과에서 keypoints를 추출\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m keypoints \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mkeypoints\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# numpy 배열로 변환하여 리스트에 추가\u001b[39;00m\n\u001b[0;32m     16\u001b[0m keypoints_list\u001b[38;5;241m.\u001b[39mappend(keypoints)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'keypoints'"
     ]
    }
   ],
   "source": [
    "# 이미지 폴더 내의 이미지를 처리하고 keypoints를 저장할 배열 초기화\n",
    "keypoints_list = []\n",
    "\n",
    "# 이미지 파일을 하나씩 처리\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(image_folder, image_file)\n",
    "\n",
    "    # 이미지를 모델로 전달하여 keypoints를 검출\n",
    "    results = model(image_path)\n",
    "    results\n",
    "\n",
    "    # 결과에서 keypoints를 추출\n",
    "    keypoints = results.keypoints.data\n",
    "\n",
    "    # numpy 배열로 변환하여 리스트에 추가\n",
    "    keypoints_list.append(keypoints)\n",
    "\n",
    "# 모든 이미지의 keypoints를 numpy 배열로 변환\n",
    "keypoints_array = np.array(keypoints_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f19dbc5-f255-4955-a5bf-68cc5ef04108",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f66cc29-39e7-4ab5-a6c3-45ef523a980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keypoints_array를 저장할 경로 설정\n",
    "output_file = os.path.join(save_path, EXC_NAME)\n",
    "\n",
    "# numpy 배열을 파일로 저장\n",
    "np.save(output_file, keypoints_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36581af9-ff97-44a8-b812-7c4227fbbe84",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 F:\\ArrayData\\Lunge\\136-1-1-05-Z39_D-0000004.jpg: 384x640 1 person, 145.2ms\n",
      "Speed: 2.0ms preprocess, 145.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict7\u001b[0m\n",
      "\n",
      "image 1/1 F:\\ArrayData\\Lunge\\136-1-1-05-Z39_D-0000005.jpg: 384x640 1 person, 116.0ms\n",
      "Speed: 1.0ms preprocess, 116.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict7\u001b[0m\n",
      "\n",
      "image 1/1 F:\\ArrayData\\Lunge\\136-1-1-05-Z39_D-0000006.jpg: 384x640 1 person, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict7\u001b[0m\n",
      "\n",
      "image 1/1 F:\\ArrayData\\Lunge\\136-1-1-05-Z39_D-0000007.jpg: 384x640 1 person, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict7\u001b[0m\n",
      "\n",
      "image 1/1 F:\\ArrayData\\Lunge\\136-1-1-05-Z39_D-0000008.jpg: 384x640 1 person, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict7\u001b[0m\n",
      "\n",
      "image 1/1 F:\\ArrayData\\Lunge\\136-1-1-05-Z39_D-0000009.jpg: 384x640 1 person, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict7\u001b[0m\n",
      "\n",
      "image 1/1 F:\\ArrayData\\Lunge\\136-1-1-05-Z39_D-0000010.jpg: 384x640 1 person, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict7\u001b[0m\n",
      "\n",
      "image 1/1 F:\\ArrayData\\Lunge\\136-1-1-05-Z39_D-0000011.jpg: 384x640 1 person, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict7\u001b[0m\n",
      "\n",
      "image 1/1 F:\\ArrayData\\Lunge\\136-1-1-05-Z39_D-0000013.jpg: 384x640 1 person, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict7\u001b[0m\n",
      "\n",
      "image 1/1 F:\\ArrayData\\Lunge\\136-1-1-05-Z39_D-0000014.jpg: 384x640 1 person, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict7\u001b[0m\n",
      "\n",
      "image 1/1 F:\\ArrayData\\Lunge\\136-1-1-05-Z39_D-0000015.jpg: 384x640 1 person, 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict7\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with open(save_path+EXC_NAME, \"w\") as file:    \n",
    "    for imgs in image_files:\n",
    "        img=os.path.join(image_folder, imgs)\n",
    "        results = model(img,save=True) \n",
    "        for r in results :\n",
    "            file.write(str(r.numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd0e9fea-9322-41f7-8947-e4aa884856d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpimg = 'F:\\\\ArrayData\\\\Lunge\\\\136-1-1-05-Z39_D-0000011.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d186236f-8d9c-46c5-adb9-90b974e7158a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 F:\\ArrayData\\Lunge\\136-1-1-05-Z39_D-0000011.jpg: 384x640 1 person, 149.0ms\n",
      "Speed: 2.0ms preprocess, 149.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " orig_img: array([[[254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [246, 245, 235],\n",
       "         [246, 245, 235],\n",
       "         [246, 245, 235]],\n",
       " \n",
       "        [[254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [246, 245, 235],\n",
       "         [246, 245, 235],\n",
       "         [246, 245, 235]],\n",
       " \n",
       "        [[254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [246, 245, 235],\n",
       "         [246, 245, 235],\n",
       "         [246, 245, 235]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [236, 234, 223],\n",
       "         [236, 234, 223],\n",
       "         [236, 234, 223]],\n",
       " \n",
       "        [[254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [235, 233, 222],\n",
       "         [235, 233, 222],\n",
       "         [235, 233, 222]],\n",
       " \n",
       "        [[254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [235, 233, 222],\n",
       "         [235, 233, 222],\n",
       "         [235, 233, 222]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: 'F:\\\\ArrayData\\\\Lunge\\\\136-1-1-05-Z39_D-0000011.jpg'\n",
       " probs: None\n",
       " save_dir: None\n",
       " speed: {'preprocess': 2.001047134399414, 'inference': 149.03521537780762, 'postprocess': 2.000093460083008}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model(tmpimg)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ddc5afe-01b6-4539-9dc3-c0576c306200",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints = results[0].keypoints.data  # [0]은 결과 리스트에서 첫 번째 요소를 가져옴\n",
    "keypoints_cpu = keypoints.cpu()  # CUDA 디바이스에서 호스트 메모리로 복사\n",
    "keypoints_np = keypoints_cpu.numpy()  # numpy 배열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "867a21e3-a222-4d4f-b50a-b1ca7d244e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[     765.32,      276.43,     0.98659],\n",
       "        [     782.45,       263.1,     0.98666],\n",
       "        [     752.56,      263.79,     0.90606],\n",
       "        [     813.47,      273.75,     0.96795],\n",
       "        [          0,           0,     0.39699],\n",
       "        [     854.17,      359.82,     0.99739],\n",
       "        [     738.48,      368.32,     0.99594],\n",
       "        [     930.88,      454.18,      0.9888],\n",
       "        [     726.27,      456.16,     0.96492],\n",
       "        [     888.39,      548.47,     0.98541],\n",
       "        [     742.73,      546.11,     0.95861],\n",
       "        [     850.91,      587.53,     0.99872],\n",
       "        [     789.13,      586.79,     0.99833],\n",
       "        [     795.63,      755.65,     0.99788],\n",
       "        [     827.55,      737.43,     0.99696],\n",
       "        [     814.14,      914.23,     0.99278],\n",
       "        [     942.31,      829.43,     0.99107]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_np"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
